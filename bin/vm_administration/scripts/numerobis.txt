#
prstat -a -s rss
#- Quick overview of top processes ordered by physical memory consumption, plus memory consumption per user. Note that if you have lots of processes all sharing (say) a 1GB bit of shard memory, each process will show up as using 1GB (very noticeable with oracle, where there can be 100 processes each with a hook into the multi-GB SGA)
#
ls -l /proc/{pid}/as
#nice easy way to see the address space (total memory usage) for a single process. Good for when you want to see the memory usage of a set of processes which is too large to fit into prstat e.g. _
#
# is apache leaking?
for pid in `pgrep httpd`
do
   ls -l /proc/$pid/as
done
#
vmstat -S 3
#Am I swapping? watch the swap in/out columns; if they’re not 0, you need more RAM
#
vmstat 3
#Am I thinking about swapping? The sr (Scan Rate) column tells you when you’re starting to run low on memory, and the kernel is scanning physical memory to find blocks that can be swapped out. c.f. Myth: Using swap is bad for performance
echo "::memstat" | mdb -k
#How much memory is being used by the kernel and/or the (UFS) file system caches? (n.b. the kernel memory usage includes the ZFS ARC cache – see below) Warning this can take several minutes to run, and sucks up a lot of CPU time.
#
kstat -m zfs
#Network
#Adapter 1:
#
#Intel PRO/1000 MT Desktop (Bridged adapter, igb1 - Ethernet)
#Adapter 2:
#
#Intel PRO/1000 MT Desktop (Host-only adapter, 'vboxnet0')
# 
#
#e1000g0: 134.245.253.5/26
#e1000g1: 192.168.56.2/24
#
#----------------------------------------------------------------------
# Grundsaetzliches:
#
# Rechnername: numerobis:
# Ausstattung:
#
#  2 * 2.27 GHz Quadcore
#  24 GB RAM
#  136 GB Plattenplatz
#
# scp -i ~/.ssh/id_uni vbox@134.245.253.4:/home/vbox/.VirtualBox/VirtualBox.xml .
# scp -i ~/.ssh/id_uni ./VirtualBox.xml vbox@134.245.253.4:/home/vbox/.VirtualBox/
#
# scp -i ~/.ssh/id_uni vbox@134.245.253.4:/home/vbox/.VirtualBox/Machines/vmmain/vmmain.xml .
# scp -i ~/.ssh/id_uni ./vmmain.xml vbox@134.245.253.4:/home/vbox/.VirtualBox/Machines/vmmain/
#
# scp -i ~/.ssh/id_uni vbox@134.245.253.4:/home/vbox/.VirtualBox/Machines/vmclient/vmclient.xml .
# scp -i ~/.ssh/id_uni ./vmclient.xml vbox@134.245.253.4:/home/vbox/.VirtualBox/Machines/vmclient/
#
# ssh vbox@134.245.253.4 -i ~/.ssh/id_uni
# ssh scadmin@134.245.253.5 -i ~/.ssh/id_uni
# vm-queue /// swc-job-queue
# scp -i ~/.ssh/id_uni consumer.jar vbox@134.245.253.4:/home/vbox/
# scp -i ~/.ssh/id_uni producer.jar scadmin@134.245.253.5:/home/scadmin/
# scp -i ~/.ssh/id_uni vmmain.ovf vbox@134.245.253.4:/home/vbox/
# scp -i ~/.ssh/id_uni vmmain.vmdk vbox@134.245.253.4:/home/vbox/
# scp -i ~/.ssh/id_uni vmclient.ovf vbox@134.245.253.4:/home/vbox/
# scp -i ~/.ssh/id_uni vmclient.vmdk vbox@134.245.253.4:/home/vbox/
#
# ----------------------------------------------------------------------
# Netzplan:
#
#       Verwaltungsbereich
#        134.245.248.0/25
#       +---------+---------+
#                 |
#                 |           s    +
#                 |               | Zugang zum Internet
#                 |15             | 134.245.253.0/26
#         1 +-----+-----+ 4       |
#      +----+ hardware  +---------+
#      |    +-----------+         |
#      |                          |
#      |                          |
#      |    +-----------+ 5       |
#      |    |  VM main  +---------+
#      |    +-----+-----+         |
#      |          | 2             |
#      |          |               |
#      |          |               +
#      |          |
#  +---+----------+----+-------+
#   192.168.56.0/24    |
#   Rechnerintern      |
#                      | dhcp
#                +-----+-----+
#                |   VM x    |
#                +-----------+
#
#----------------------------------------------------------------------
# Filesystem:
#
# Alles sollte nur unter dem User 'vbox' ablaufen. VirtualBox legt dann
# seine Daten standardmaessig unter dem Verzeichnis
#
#  /home/vbox/.VirtualBox
#
# ab. Da wir fuer die eigentlichen Diskimages das ZFS Feature des
# Klonens nutzen wollen, muesse diese in einem eigenen Filesystem
# liegen. Dafuer ist bereits
#
#  /home/vbox/harddisks
#
# angelegt worden.
#
# Ab hier muss fuer jedes Diskimage ein eigenes weiteres Filesystem
# angelegt werden. Diese Images sollen NIE direkt benutzt werden. Statt
# dessen sollte immer erst ein Snapshot/Clone angelegt werden. Das hat 
# den Vorteil, dass das Original immer als Fallback zur Verfuegung 
# steht.
#
#----------------------------------------------------------------------
# Hier das ganze mal am Beispiel OpenSolaris demonstriert:
#
# Zuerst muss ein neues Filesystem angelegt werden
#
zfs create zpool1/vbox/harddisks/opensolaris
zfs list -r zpool1
# NAME                                      USED  AVAIL  REFER  MOUNTPOINT
# zpool1                                   13.2G   121G  6.97G  /zpool1
# zpool1/vbox                              6.24G   121G  4.19G  /zpool1/vbox
# zpool1/vbox/harddisks                    2.05G   121G    23K  /zpool1/vbox/harddisks
# zpool1/vbox/harddisks/opensolaris        2.05G   121G  2.05G  /zpool1/vbox/harddisks/opensolaris
#
# Dann erst kann das Image dort abgelegt werden
# 
cd ~/harddisks/opensolaris
#
#-% MOVE VBOX IMAGES START
# Exportieren und .vdi nach .vmdk konvertieren:
# VBoxManage internalcommands converthd -srcformat VDI -dstformat VMDK SC\ VM\ Main.vdi vmmain.vmdk
#
# Mit SCP kopieren:
# scp -i ~/.ssh/id_uni vmmain.vmdk vbox@134.245.253.4:/home/vbox
#
# In VirtualBox importieren:
#
# .vmdk nach .vdi konvertieren:
# VBoxManage internalcommands converthd -srcformat VMDK -dstformat VDI vmmain.vmdk vmmain.vdi
#
# Die HDUUID muss in der Machine xml noch aktualisiert.
# -% MOVE VBOX IMAGES END
#
cp <irgendwoher>/OpenSolaris.vdi .
#
#-% BEGIN EDIT
#
# Parameter der VM ändern:
# VBoxManage guestproperty enumerate vmmain
# VBoxManage import vmmain.ovf
#
# VBoxManage modifyvm vmmain --hda none
# VBoxManage modifyvm vmmain --hda /home/vbox/vmmain.vdi
# VBoxManage modifyvm vmmain --cpus 2 --memory 4096
# VBoxManage modifyvm vmmain --nic1 bridged --nictype1 82540EM --cableconnected1 on --bridgeadapter1 igb1\ -\ Ethernet --macaddress1 auto
# VBoxManage modifyvm vmmain --nic2 hostonly --nictype2 82540EM --cableconnected2 on --macaddress2 auto --hostonlyadapter2 vboxnet0
# VBoxManage modifyvm vmclient --nic1 hostonly --nictype1 82540EM --cableconnected1 on --macaddress1 auto --hostonlyadapter1 vboxnet0
#
# SIOCDELRT
#
# VBoxManage list vms
# VBoxManage showvminfo vmmain
# VBoxManage controlvm vmmain poweroff
# VBoxManage startvm vmmain --type headless
# VBoxManage list runningvms
# VBoxManage unregistervm vmmain -delete
#
# -% END EDIT
#
#ACHTUNG: jedes Image braucht eine eigene UUID
#
VBoxManage internalcommands sethduuid *.vdi
# VirtualBox Command Line Management Interface Version 3.0.8
# (C) 2005-2009 Sun Microsystems, Inc.
# All rights reserved.
#
# UUID changed to: cd6f93b1-cefd-405a-88ba-b55661928bc3
#
# Jetzt wird zuerst ein Snapshot des Originals angelegt. Das muss sein,
# da Clone nur von Snapshots erzeugt werden koennen
#
zfs snapshot zpool1/vbox/harddisks/vmclient@kopie
zfs list -r zpool1
# NAME                                      USED  AVAIL  REFER  MOUNTPOINT
# zpool1                                   13.2G   121G  6.97G  /zpool1
# zpool1/vbox                              6.24G   121G  4.19G  /zpool1/vbox
# zpool1/vbox/harddisks                    2.05G   121G    23K  /zpool1/vbox/harddisks
# zpool1/vbox/harddisks/opensolaris        2.05G   121G  2.05G  /zpool1/vbox/harddisks/opensolaris
# zpool1/vbox/harddisks/opensolaris@kopie      0      -  2.05G  -
#
# und dann den Clone erzeugen
zfs clone zpool1/vbox/harddisks/vmclient@kopie zpool1/vbox/harddisks/vmclient-1
zfs list -r zpool1
# NAME                                      USED  AVAIL  REFER  MOUNTPOINT
# zpool1                                   13.2G   121G  6.97G  /zpool1
# zpool1/vbox                              6.24G   121G  4.19G  /zpool1/vbox
# zpool1/vbox/harddisks                    2.05G   121G    23K  /zpool1/vbox/harddisks
# zpool1/vbox/harddisks/opensolaris        2.05G   121G  2.05G  /zpool1/vbox/harddisks/opensolaris
# zpool1/vbox/harddisks/opensolaris@kopie      0      -  2.05G  -
# zpool1/vbox/harddisks/opensolaris-1          0   121G  2.05G  /zpool1/vbox/harddisks/opensolaris-1
#
# dieser Clone kann beschrieben werden, und sollte sofort mit einer eigenen
# UUID versorgt werden
#
cd ../*1
# /home/vbox/harddisks/opensolaris-1
#
ls -l
# -rw-------   1 vbox     vbox     3845210624 Oct 15 12:42 OpenSolaris.vdi
#
VBoxManage internalcommands sethduuid OpenSolaris.vdi
# VirtualBox Command Line Management Interface Version 3.0.8
# (C) 2005-2009 Sun Microsystems, Inc.
# All rights reserved.
#
# UUID changed to: fcafca0b-3e77-4259-a954-01d4ab5e4954
#
zfs list -r zpool1
# NAME                                      USED  AVAIL  REFER  MOUNTPOINT
# zpool1                                   13.2G   121G  6.97G  /zpool1
# zpool1/vbox                              6.24G   121G  4.19G  /zpool1/vbox
# zpool1/vbox/harddisks                    2.05G   121G    24K  /zpool1/vbox/harddisks
# zpool1/vbox/harddisks/opensolaris        2.05G   121G  2.05G  /zpool1/vbox/harddisks/opensolaris
# zpool1/vbox/harddisks/opensolaris@kopie      0      -  2.05G  -
# zpool1/vbox/harddisks/opensolaris-1      54.5K   121G  2.05G  /zpool1/vbox/harddisks/opensolaris-1
#
# Wie man gut erkennen kann, belegt der Clone statt 2GB nur 55KB und kann 
# trotzdem voellig unabhaengig vom Original genutzt werden.
#
# Bei Bedarf ist schnell eine zweite Kopie erstellt
#
zfs clone zpool1/vbox/harddisks/vmmain@kopie zpool1/vbox/harddisks/vmmain-2
cd ../*2
VBoxManage internalcommands sethduuid OpenSolaris.vdi
# VirtualBox Command Line Management Interface Version 3.0.8
# (C) 2005-2009 Sun Microsystems, Inc.
# All rights reserved.
#
# UUID changed to: 55cec833-3685-483b-9a29-e90cf9b33800
#
zfs list -r zpool1
# NAME                                      USED  AVAIL  REFER  MOUNTPOINT
# zpool1                                   13.2G   121G  6.97G  /zpool1
# zpool1/vbox                              6.24G   121G  4.19G  /zpool1/vbox
# zpool1/vbox/harddisks                    2.05G   121G    25K  /zpool1/vbox/harddisks
# zpool1/vbox/harddisks/opensolaris        2.05G   121G  2.05G  /zpool1/vbox/harddisks/opensolaris
# zpool1/vbox/harddisks/opensolaris@kopie      0      -  2.05G  -
# zpool1/vbox/harddisks/opensolaris-1      54.5K   121G  2.05G  /zpool1/vbox/harddisks/opensolaris-1
# zpool1/vbox/harddisks/opensolaris-2      54.5K   121G  2.05G  /zpool1/vbox/harddisks/opensolaris-2
#
#----------------------------------------------------------------------
# TODO
#
# Der Zugang zum vbox-User sollte niemals interaktiv passieren. Dazu
# muesste folgendes moeglich sein:
#
# 1. ablegen neuer virtueller Maschinen
# 2. automatischen starten dieser virtuellen Maschinen
# 3. loeschen von virtuellen Maschinen
#
# Geklaert werden muss noch, wer evtl. noetige Updates des Betriebs-
# system auf der 'VM main' einspielt.
#
# ----------------------------------------------------------------------

